{"version":3,"sources":["speech.babel.js"],"names":["openSpeechRecognition","window","SpeechRecognition","webkitSpeechRecognition","recognition","language","speech","callback","addEventListener","e","transcript","Array","from","results","map","result","join","$","text","isFinal","stop","start","speechClick","console","log","sendText","data","message","context","JSON","stringify","ajax","type","url","success","res","resp","output","msg","SpeechSynthesisUtterance","speechSynthesis","speak","uploadPic","fileTrigger","error","err","click","change","sendFile","pic","document","keypress","which"],"mappings":"YAAA,SAASA,yBACLC,OAAOC,kBAAoBD,OAAOC,mBAAqBD,OAAOE,uBAC9D,IAAMC,GAAc,GAAIF,kBAIxB,OADAE,GAAYC,SAAW,KAChBD,EAGX,QAASE,QAAOC,GACZ,GAAIH,GAAcJ,uBAClBI,GAAYI,iBAAiB,SAAU,SAAAC,GACnC,GAAIC,GAAaC,MAAMC,KAAKH,EAAEI,SAC7BC,IAAI,SAAAC,GAAA,MAAUA,GAAO,KACrBD,IAAI,SAAAC,GAAA,MAAUA,GAAOL,aACrBM,KAAK,GAENC,GAAE,WAAWC,KAAKR,GAEdD,EAAEI,QAAQ,GAAGM,UACbZ,EAASG,GACTN,EAAYgB,UAIpBhB,EAAYiB,QAGhB,QAASC,eACLC,QAAQC,IAAI,WACZP,EAAE,WAAWC,KAAK,IAClBZ,OAAO,SAASY,GACZO,SAASP,KAMjB,QAASO,UAASP,GACd,GAAIQ,IACIC,QAAST,EACTU,QAASC,KAAKC,UAAUF,SAEhCX,GAAEc,MACEC,KAAM,OACNC,IAAK,gBACLP,KAAMA,EACNQ,QAAS,SAASC,GACd,GAAIC,GAAOD,EAAIE,OAAOnB,KAAK,EAC3BU,SAAUO,EAAIP,QACdL,QAAQC,IAAII,SACZL,QAAQC,IAAIY,EAEZ,IAAIE,GAAM,GAAIC,0BAAyBH,EACvCnC,QAAOuC,gBAAgBC,MAAMH,GAEJ,QAArBV,QAAQc,YACRd,QAAQc,UAAY,QACpBC,gBAGRC,MAAO,SAASC,GACZtB,QAAQC,IAAIqB,MAMxB,QAASF,eACLpB,QAAQC,IAAI,aACZP,EAAE,eAAe6B,QAGrB,QAASJ,aAELzB,EAAE,eAAe6B,QACjB7B,EAAE,eAAe8B,OAAO,SAASrB,GAC7BH,QAAQC,IAAIP,EAAE,kBAKtB,QAAS+B,UAASC,GACdhC,EAAEc,MACEC,KAAM,OACNC,IAAK,qBACLP,MACIE,QAASC,KAAKC,UAAUF,SACxBqB,IAAKA,GAETf,QAAS,SAASC,GACd,GAAIC,GAAOD,EAAIE,OAAOnB,KAAK,EAC3BU,SAAUO,EAAIP,QACdL,QAAQC,IAAII,SACZL,QAAQC,IAAIY,EAEZ,IAAIE,GAAM,GAAIC,0BAAyBH,EACvCnC,QAAOuC,gBAAgBC,MAAMH,GAEzBV,QAAQc,YACRd,QAAQc,WAAY,EACpBA,cAGRE,MAAO,SAASC,GACZtB,QAAQC,IAAIqB,MArExB,GAAIjB,QA0EJX,GAAEiC,UAAUC,SAAS,SAAS1C,GAC1Bc,QAAQC,IAAIf,EAAE2C,OACF,KAAX3C,EAAE2C,OACHV","file":"speech.babel.js","sourcesContent":["function openSpeechRecognition() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    const recognition = new SpeechRecognition();\n    // recognition.continuous = true;\n    // recognition.interimResults = true;\n    recognition.language = 'de';\n    return recognition;\n}\n\nfunction speech(callback){\n    let recognition = openSpeechRecognition();\n    recognition.addEventListener('result', e => {\n        let transcript = Array.from(e.results)\n        .map(result => result[0])\n        .map(result => result.transcript)\n        .join('');\n\n        $('#mytext').text(transcript);\n\n        if (e.results[0].isFinal) {\n            callback(transcript);\n            recognition.stop();\n\n        }\n    });\n    recognition.start();\n}\n\nfunction speechClick(){\n    console.log(\"clicked\");\n    $('#mytext').text(\"\");\n    speech(function(text){\n        sendText(text);\n    });\n}\n\nvar context;\n\nfunction sendText(text){\n    var data = {\n            message: text, \n            context: JSON.stringify(context)\n        }\n    $.ajax({\n        type: \"POST\",\n        url: \"/conversation\",\n        data: data,\n        success: function(res){\n            var resp = res.output.text[0];\n            context = res.context;\n            console.log(context);\n            console.log(resp);\n\n            var msg = new SpeechSynthesisUtterance(resp);\n            window.speechSynthesis.speak(msg);\n\n            if (context.uploadPic == \"true\") {\n                context.uploadPic = \"false\";\n                fileTrigger();\n            }\n        },\n        error: function(err){\n            console.log(err);\n        }\n    });\n}\n\n\nfunction fileTrigger(){\n    console.log(\"triggered\");\n    $(\"#watsonFile\").click();\n}\n\nfunction uploadPic() {\n\n    $(\"#watsonFile\").click();\n    $(\"#watsonFile\").change(function(data){\n        console.log($(\"#watsonFile\"));\n    });\n}\n\n\nfunction sendFile(pic){\n    $.ajax({\n        type: \"POST\",\n        url: \"/visualRecognition\",\n        data: {\n            context: JSON.stringify(context),\n            pic: pic\n        },\n        success: function(res){\n            var resp = res.output.text[0];\n            context = res.context;\n            console.log(context);\n            console.log(resp);\n\n            var msg = new SpeechSynthesisUtterance(resp);\n            window.speechSynthesis.speak(msg);\n\n            if (context.uploadPic) {\n                context.uploadPic = false;\n                uploadPic();\n            }\n        },\n        error: function(err){\n            console.log(err);\n        }\n    });\n}\n\n$(document).keypress(function(e) {\n    console.log(e.which);\n  if(e.which == 102) {\n    uploadPic();\n  }\n});\n"]}