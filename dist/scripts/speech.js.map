{"version":3,"sources":["speech.babel.js"],"names":["openSpeechRecognition","window","SpeechRecognition","webkitSpeechRecognition","recognition","language","displayMessage","reply","input","$","append","speech","callback","addEventListener","e","transcript","Array","from","results","map","result","join","text","isFinal","stop","start","speechClick","console","log","sendText","data","message","context","JSON","stringify","ajax","type","url","success","res","resp","output","msg","SpeechSynthesisUtterance","speechSynthesis","speak","uploadPic","fileTrigger","error","err","click","change","sendFile","pic","document","keypress","which"],"mappings":"YAAA,SAASA,yBACLC,OAAOC,kBAAoBD,OAAOC,mBAAqBD,OAAOE,uBAC9D,IAAMC,GAAc,GAAIF,kBAIxB,OADAE,GAAYC,SAAW,KAChBD,EAGX,QAASE,gBAAeC,EAAOC,GACxBD,EACCE,EAAE,eAAeC,OAAO,qCAAuCH,EAAQ,eAEvEE,EAAE,eAAeC,OAAO,oCAAsCF,EAAQ,eAI9E,QAASG,QAAOC,GACZ,GAAIR,GAAcJ,uBAClBI,GAAYS,iBAAiB,SAAU,SAAAC,GACnC,GAAIC,GAAaC,MAAMC,KAAKH,EAAEI,SAC7BC,IAAI,SAAAC,GAAA,MAAUA,GAAO,KACrBD,IAAI,SAAAC,GAAA,MAAUA,GAAOL,aACrBM,KAAK,GAENZ,GAAE,WAAWa,KAAKP,GAClBT,gBAAe,EAAOS,GAElBD,EAAEI,QAAQ,GAAGK,UACbX,EAASG,GACTX,EAAYoB,UAIpBpB,EAAYqB,QAGhB,QAASC,eACLC,QAAQC,IAAI,WACZnB,EAAE,WAAWa,KAAK,IAClBX,OAAO,SAASW,GACZO,SAASP,KAMjB,QAASO,UAASP,GACd,GAAIQ,IACIC,QAAST,EACTU,QAASC,KAAKC,UAAUF,SAEhCvB,GAAE0B,MACEC,KAAM,OACNC,IAAK,gBACLP,KAAMA,EACNQ,QAAS,SAASC,GACd,GAAIC,GAAOD,EAAIE,OAAOnB,KAAK,EAC3BU,SAAUO,EAAIP,QACdL,QAAQC,IAAII,SACZL,QAAQC,IAAIY,GACZlC,eAAekC,GAAM,EAErB,IAAIE,GAAM,GAAIC,0BAAyBH,EACvCvC,QAAO2C,gBAAgBC,MAAMH,GAEJ,QAArBV,QAAQc,YACRd,QAAQc,UAAY,QACpBC,gBAGRC,MAAO,SAASC,GACZtB,QAAQC,IAAIqB,MAMxB,QAASF,eACLpB,QAAQC,IAAI,aACZnB,EAAE,eAAeyC,QAGrB,QAASJ,aAELrC,EAAE,eAAeyC,QACjBzC,EAAE,eAAe0C,OAAO,SAASrB,GAC7BH,QAAQC,IAAInB,EAAE,kBAKtB,QAAS2C,UAASC,GACd5C,EAAE0B,MACEC,KAAM,OACNC,IAAK,qBACLP,MACIE,QAASC,KAAKC,UAAUF,SACxBqB,IAAKA,GAETf,QAAS,SAASC,GACd,GAAIC,GAAOD,EAAIE,OAAOnB,KAAK,EAC3BU,SAAUO,EAAIP,QACdL,QAAQC,IAAII,SACZL,QAAQC,IAAIY,EAEZ,IAAIE,GAAM,GAAIC,0BAAyBH,EACvCvC,QAAO2C,gBAAgBC,MAAMH,GAEzBV,QAAQc,YACRd,QAAQc,WAAY,EACpBA,cAGRE,MAAO,SAASC,GACZtB,QAAQC,IAAIqB,MAtExB,GAAIjB,QA2EJvB,GAAE6C,UAAUC,SAAS,SAASzC,GAC1Ba,QAAQC,IAAId,EAAE0C,OACF,KAAX1C,EAAE0C,OACHV","file":"speech.babel.js","sourcesContent":["function openSpeechRecognition() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    const recognition = new SpeechRecognition();\n    // recognition.continuous = true;\n    // recognition.interimResults = true;\n    recognition.language = 'de';\n    return recognition;\n}\n\nfunction displayMessage(reply, input) {\n    if(reply) {\n        $('.messageBox').append('<div class=\"is-12 start left\"><h2>' + reply + '</h2></div>');\n    } else {\n        $('.messageBox').append('<div class=\"is-12 end right\"><h2>' + input + '</h2></div>');\n    }\n}\n\nfunction speech(callback){\n    let recognition = openSpeechRecognition();\n    recognition.addEventListener('result', e => {\n        let transcript = Array.from(e.results)\n        .map(result => result[0])\n        .map(result => result.transcript)\n        .join('');\n\n        $('#mytext').text(transcript);\n        displayMessage(false, transcript);\n\n        if (e.results[0].isFinal) {\n            callback(transcript);\n            recognition.stop();\n\n        }\n    });\n    recognition.start();\n}\n\nfunction speechClick(){\n    console.log(\"clicked\");\n    $('#mytext').text(\"\");\n    speech(function(text){\n        sendText(text);\n    });\n}\n\nvar context;\n\nfunction sendText(text){\n    var data = {\n            message: text, \n            context: JSON.stringify(context)\n        }\n    $.ajax({\n        type: \"POST\",\n        url: \"/conversation\",\n        data: data,\n        success: function(res){\n            var resp = res.output.text[0];\n            context = res.context;\n            console.log(context);\n            console.log(resp);\n            displayMessage(resp, false);\n\n            var msg = new SpeechSynthesisUtterance(resp);\n            window.speechSynthesis.speak(msg);\n\n            if (context.uploadPic == \"true\") {\n                context.uploadPic = \"false\";\n                fileTrigger();\n            }\n        },\n        error: function(err){\n            console.log(err);\n        }\n    });\n}\n\n\nfunction fileTrigger(){\n    console.log(\"triggered\");\n    $(\"#watsonFile\").click();\n}\n\nfunction uploadPic() {\n\n    $(\"#watsonFile\").click();\n    $(\"#watsonFile\").change(function(data){\n        console.log($(\"#watsonFile\"));\n    });\n}\n\n\nfunction sendFile(pic){\n    $.ajax({\n        type: \"POST\",\n        url: \"/visualRecognition\",\n        data: {\n            context: JSON.stringify(context),\n            pic: pic\n        },\n        success: function(res){\n            var resp = res.output.text[0];\n            context = res.context;\n            console.log(context);\n            console.log(resp);\n\n            var msg = new SpeechSynthesisUtterance(resp);\n            window.speechSynthesis.speak(msg);\n\n            if (context.uploadPic) {\n                context.uploadPic = false;\n                uploadPic();\n            }\n        },\n        error: function(err){\n            console.log(err);\n        }\n    });\n}\n\n$(document).keypress(function(e) {\n    console.log(e.which);\n  if(e.which == 102) {\n    uploadPic();\n  }\n});\n"]}